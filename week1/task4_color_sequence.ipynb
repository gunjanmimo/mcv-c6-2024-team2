{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import data_handler, frame_utils, metrics\n",
    "\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir\n",
    "XML_annotation_path =  \"/home/mimo/Desktop/MS CV/C6/week_1/data/ai_challenge_s03_c010-full_annotation.xml\"\n",
    "video_path = \"/home/mimo/Desktop/MS CV/C6/week_1/data/AICity_data/AICity_data/train/S03/c010/vdo.avi\"\n",
    "extracted_frame_dir = \"/home/mimo/Desktop/MS CV/C6/week_1/data/extracted_frames/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation data\n",
    "frame_with_movement_data = data_handler.parse_xml_annotations(\n",
    "    xml_file=XML_annotation_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame_paths, test_frame_paths = data_handler.split_train_test_frames(\n",
    "    data_dir=extracted_frame_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gaussian(train_frame_paths,target_brightness=15, color_space=\"RGB\"):\n",
    "    train_frames = [cv2.imread(frame_path) for frame_path in tqdm(train_frame_paths)]\n",
    "\n",
    "    # fix the illumination of all the frames\n",
    "    train_frames = [\n",
    "        frame_utils.adjust_brightness(frame, target_brightness=target_brightness)\n",
    "        for frame in tqdm(train_frames)\n",
    "    ]\n",
    "\n",
    "    train_frames = [\n",
    "        frame_utils.convert_color_space(frame, color_space) for frame in tqdm(train_frames)\n",
    "    ]\n",
    "\n",
    "    # Calculate the mean and variance across the color channels of the training frames\n",
    "    mean = np.mean(train_frames, axis=(0, 1, 2))\n",
    "    variance = np.var(train_frames, axis=(0, 1, 2))\n",
    "\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def calculate_metrics(detections, ground_truth, iou_threshold=0.5):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for det in detections:\n",
    "        matched = False\n",
    "        for ann in ground_truth:\n",
    "            iou = metrics.calculate_iou(\n",
    "                (\n",
    "                    det[\"xtl\"],\n",
    "                    det[\"ytl\"],\n",
    "                    det[\"xbr\"] - det[\"xtl\"],\n",
    "                    det[\"ybr\"] - det[\"ytl\"],\n",
    "                ),\n",
    "                (\n",
    "                    ann[\"xtl\"],\n",
    "                    ann[\"ytl\"],\n",
    "                    ann[\"xbr\"] - ann[\"xtl\"],\n",
    "                    ann[\"ybr\"] - ann[\"ytl\"],\n",
    "                ),\n",
    "            )\n",
    "            if iou >= iou_threshold:\n",
    "                true_positives += 1\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            false_positives += 1\n",
    "\n",
    "    false_negatives = len(ground_truth) - true_positives\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        [1] * true_positives + [0] * false_positives,\n",
    "        [1] * true_positives + [0] * false_negatives,\n",
    "        average=\"binary\",\n",
    "        pos_label=1,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(\n",
    "    train_frame_paths,\n",
    "    test_frame_paths,\n",
    "    frame_with_movement_data,\n",
    "    color_space,\n",
    "    alpha,\n",
    "    rho=None,\n",
    "    iou_threshold=0.5,target_brightness = 150\n",
    "):\n",
    "    if rho is None: \n",
    "\n",
    "        mean, variance = train_gaussian(train_frame_paths, color_space)\n",
    "\n",
    "        print(\"::EXTRACTING FOREGROUND\")\n",
    "        foreground_masks = []\n",
    "        for path in tqdm(test_frame_paths):\n",
    "            frame = cv2.imread(path)\n",
    "            # adjust brightness\n",
    "            frame = frame_utils.adjust_brightness(\n",
    "                frame, target_brightness=target_brightness\n",
    "            )\n",
    "            frame = frame_utils.convert_color_space(frame, color_space=color_space)\n",
    "            # Calculate the absolute difference between the current frame and the model\n",
    "            abs_diff = np.abs(frame - mean)\n",
    "            # Classify as foreground if the difference exceeds the threshold (alpha * (variance + 2))\n",
    "            threshold = alpha * (np.sqrt(variance) + 2)\n",
    "            foreground_mask = abs_diff >= threshold\n",
    "            foreground_masks.append(foreground_mask)\n",
    "\n",
    "    else: \n",
    "\n",
    "        mean, variance = train_gaussian(train_frame_paths, color_space)\n",
    "        print(\"::EXTRACTING FOREGROUND\")\n",
    "        foreground_masks = []\n",
    "        for path in tqdm(test_frame_paths):\n",
    "            frame = cv2.imread(path)\n",
    "\n",
    "            # adjust brightness\n",
    "            frame = frame_utils.adjust_brightness(\n",
    "                frame, target_brightness=target_brightness\n",
    "            )\n",
    "            frame = frame_utils.convert_color_space(frame, color_space=color_space)\n",
    "            # Calculate the absolute difference between the current frame and the model\n",
    "            abs_diff = np.abs(frame - mean)\n",
    "            # Classify as foreground if the difference exceeds the threshold (alpha * (variance + 2))\n",
    "            threshold = alpha * (np.sqrt(variance) + 2)\n",
    "            foreground_mask = abs_diff >= threshold\n",
    "            foreground_masks.append(foreground_mask)\n",
    "\n",
    "            # Get indices of background pixels\n",
    "            background_indices = np.where(~foreground_mask)\n",
    "\n",
    "            # Update the model for the background pixels\n",
    "            mean[background_indices] = (\n",
    "                rho * frame[background_indices] + (1 - rho) * mean[background_indices]\n",
    "            )\n",
    "            variance[background_indices] = (\n",
    "                rho * ((frame[background_indices] - mean[background_indices]) ** 2)\n",
    "                + (1 - rho) * variance[background_indices]\n",
    "            )\n",
    "    results = []\n",
    "    for f_mask in tqdm(foreground_masks): \n",
    "        f_mask_gray = cv2.cvtColor(f_mask.astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "        # Use connected components to extract individual detections\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "            f_mask.astype(np.uint8), connectivity=8, ltype=cv2.CV_32S\n",
    "        )\n",
    "\n",
    "        detections = []\n",
    "        # threshold to consider BBOX \n",
    "        min_detection_area = 150\n",
    "\n",
    "        # Check if the area of the detection is considerably bigger than the corresponding annotation\n",
    "        for i in range(1, num_labels):\n",
    "            x, y, w, h, area = stats[i]\n",
    "            if area < min_detection_area:\n",
    "                continue\n",
    "\n",
    "            # Append detection\n",
    "            detections.append(\n",
    "                {\n",
    "                    \"xtl\": x,\n",
    "                    \"ytl\": y,\n",
    "                    \"xbr\": x + w,\n",
    "                    \"ybr\": y + h,\n",
    "                    \"confidence\": 1,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Calculate metrics for each frame\n",
    "        precision, recall, f1 = calculate_metrics(\n",
    "            detections, frame_with_movement_data[path], iou_threshold\n",
    "        )\n",
    "        results.append((precision, recall, f1))\n",
    "\n",
    "        # Update the model for the background pixels if rho is specified\n",
    "        if rho is not None:\n",
    "            background_indices = np.where(~foreground_mask)\n",
    "            mean[background_indices] = (\n",
    "                rho * frame[background_indices] + (1 - rho) * mean[background_indices]\n",
    "            )\n",
    "            variance[background_indices] = (\n",
    "                rho * ((frame[background_indices] - mean[background_indices]) ** 2)\n",
    "                + (1 - rho) * variance[background_indices]\n",
    "            )\n",
    "\n",
    "    # Calculate mean average precision (mAP) across all frames\n",
    "    mAP = np.mean([precision for precision, _, _ in results])\n",
    "    # Calculate mean F1 score across all frames\n",
    "    mean_F1 = np.mean([f1 for _, _, f1 in results])\n",
    "\n",
    "    return mAP, mean_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(\n",
    "    train_frame_paths=train_frame_paths,\n",
    "    test_frame_paths=test_frame_paths,\n",
    "    frame_with_movement_data=frame_with_movement_data,\n",
    "    color_space=\"RGB\",\n",
    "    alpha=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_colorspace = [\n",
    "    \"RGB\",\n",
    "    \"HSV\",\n",
    "    \"Lab\",\n",
    "    \"YCrCb\",\n",
    "    \"XYZ\",\n",
    "    \"Luv\",\n",
    "    \"HLS\",\n",
    "    \"YUV\",\n",
    "    \"GRAY\",\n",
    "]\n",
    "available_alpha = [i for i in range(1, 31, 5)]  \n",
    "available_rho = [i / 5 for i in range(0, 10)]  \n",
    "available_target_brightness = list(\n",
    "    range(100, 201, 20)\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM SEARCH\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define a set to keep track of used combinations\n",
    "used_combinations = set()\n",
    "\n",
    "\n",
    "def objective():\n",
    "    selected_colorspace = random.choice(available_colorspace)\n",
    "    selected_alpha = random.choice(available_alpha)\n",
    "    selected_rho = random.choice(available_rho)\n",
    "    selected_target_brightness = random.choice(available_target_brightness)\n",
    "\n",
    "    # Check if the combination is already used, if yes, select a new one\n",
    "    while (\n",
    "        selected_colorspace,\n",
    "        selected_alpha,\n",
    "        selected_rho,\n",
    "        selected_target_brightness,\n",
    "    ) in used_combinations:\n",
    "        selected_colorspace = random.choice(available_colorspace)\n",
    "        selected_alpha = random.choice(available_alpha)\n",
    "        selected_rho = random.choice(available_rho)\n",
    "        selected_target_brightness = random.choice(available_target_brightness)\n",
    "\n",
    "    used_combinations.add(\n",
    "        (selected_colorspace, selected_alpha, selected_rho, selected_target_brightness)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        ap, f1_score_max = evaluation(\n",
    "            train_frame_paths=train_frame_paths,\n",
    "            test_frame_paths=test_frame_paths,\n",
    "            frame_with_movement_data=frame_with_movement_data,\n",
    "            color_space=\"RGB\",\n",
    "            alpha=4,\n",
    "        )\n",
    "\n",
    "        \n",
    "        data = [\n",
    "            [\"Colorspace\", selected_colorspace],\n",
    "            [\"Alpha\", selected_alpha],\n",
    "            [\"Rho\", selected_rho],\n",
    "            [\"Target Brightness\", selected_target_brightness],\n",
    "            [\"MAP\", f\"{ap * 100 if ap is not None else 0}\"],\n",
    "            [\"F1 Score Max\", f\"{f1_score_max * 100 if f1_score_max is not None else 0}\"]\n",
    "        ]\n",
    "\n",
    "        # Print the data in table format\n",
    "        print(tabulate(data, headers=[\"Parameter\", \"Value\"]))\n",
    "\n",
    "        return ap * 100\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "num_trials = 30\n",
    "for i in range(num_trials):\n",
    "    print(f\"Trial {i+1}/{num_trials}:\")\n",
    "    objective()  \n",
    "    print(\"----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
